{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working with VizWiz dataset\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "base_url = 'https://ivc.ischool.utexas.edu/VizWiz/data'\n",
    "img_dir = '%s/Images/' %base_url\n",
    "\n",
    "split_train = 'train'\n",
    "split_val = 'val'\n",
    "split_test = 'test'\n",
    "\n",
    "trainFile = '%s/Annotations/%s.json' %(base_url, split_train)\n",
    "trainData = requests.get(trainFile, allow_redirects = True)\n",
    "valFile = '%s/Annotations/%s.json' %(base_url, split_val)\n",
    "valData = requests.get(valFile, allow_redirects = True)\n",
    "testFile = '%s/Annotations/%s.json' %(base_url, split_test)\n",
    "testData = requests.get(valFile, allow_redirects = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = trainData.json()\n",
    "validationData = valData.json()\n",
    "testingData = testData.json()\n",
    "\n",
    "listQuestion = []\n",
    "listLabel = []\n",
    "for vq in trainingData[0:800]:\n",
    "    question = vq['question']\n",
    "    label = vq['answerable']\n",
    "    listQuestion.append(question)\n",
    "    listLabel.append(label)\n",
    "\n",
    "listValQuestion = []\n",
    "listValLabel = []\n",
    "for vq in validationData[0:300]:\n",
    "    question_val = vq['question']\n",
    "    label_val = vq['answerable']\n",
    "    listValQuestion.append(question_val)\n",
    "    listValLabel.append(label_val)\n",
    "\n",
    "listTestQuestion = []\n",
    "for vq in testingData[0:100]:\n",
    "    question_test = vq['question']\n",
    "    listTestQuestion.append(question_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import \n",
    "allQuestions = listQuestion + listValQuestion + listTestQuestion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrive file from URL and store it locally\n",
    "split = 'train'\n",
    "trainFile = '%s/Annotations/%s.json' %(base_url, split_train)\n",
    "trainData = requests.get(trainFile, allow_redirects = True)\n",
    "print(trainFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the local file\n",
    "numTrainVQs = 4\n",
    "trainingData = trainData.json()\n",
    "for vq in trainingData[0:numTrainVQs]:\n",
    "    image_name = vq['image']\n",
    "    question = vq['question']\n",
    "    label = vq['answerable']\n",
    "    print(image_name)\n",
    "    print(question)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'val'\n",
    "valFile = '%s/Annotations/%s.json' %(base_url, split)\n",
    "valData = requests.get(valFile, allow_redirects = True)\n",
    "print(valFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numValVQs = 3\n",
    "validationData = valData.json()\n",
    "for vq in validationData[0:numValVQs]:\n",
    "    image_name = vq['image']\n",
    "    question = vq['question']\n",
    "    label = vq['answerable']\n",
    "    print(image_name)\n",
    "    print(question)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's the name of this product?\n",
      "[0, 0]\n",
      "https://ivc.ischool.utexas.edu/VizWiz/data/Images/VizWiz_train_000000000000.jpg \n",
      "\n",
      "Can you tell me what is in this can please?\n",
      "[0, 0]\n",
      "https://ivc.ischool.utexas.edu/VizWiz/data/Images/VizWiz_train_000000000001.jpg \n",
      "\n",
      "Is this enchilada sauce or is this tomatoes?  Thank you.\n",
      "[0, 0]\n",
      "https://ivc.ischool.utexas.edu/VizWiz/data/Images/VizWiz_train_000000000002.jpg \n",
      "\n",
      "What is the captcha on this screenshot?\n",
      "[0, 0]\n",
      "https://ivc.ischool.utexas.edu/VizWiz/data/Images/VizWiz_train_000000000003.jpg \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Extract features to describe the questions\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "def extract_language_features(question):\n",
    "    #Preprocessing questions\n",
    "    question = question.lower()\n",
    "    \n",
    "    words = question.split()\n",
    "    num_unique_words = len(set(words))\n",
    "    num_words = len(words)\n",
    "    rate = num_unique_words/num_words\n",
    "    \n",
    "    partsOfSpeechTag = nltk.pos_tag(words)\n",
    "    tag_fd = nltk.FreqDist(partsOfSpeechTag)\n",
    "    determinerCount = tag_fd['DT']\n",
    "    verbCount = tag_fd['VB']\n",
    "    \n",
    "    #tokens=nltk.word_tokenize(words)\n",
    "    fdist = FreqDist(words)\n",
    "\n",
    "    #tokenized_question\n",
    "    \n",
    "    featureVector = [determinerCount, verbCount]\n",
    "    return featureVector\n",
    "\n",
    "numVQs = 4\n",
    "for vq in trainingData[0:numVQs]:\n",
    "    #Question features\n",
    "    question = vq['question']\n",
    "    print(question)\n",
    "    questionFeature = extract_language_features(question)\n",
    "    print(questionFeature)\n",
    "    \n",
    "    image_name = vq['image']\n",
    "    image_url = img_dir + image_name\n",
    "    print(image_url, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00779634 0.00823141 0.00718225 ... 0.         0.         0.        ]\n",
      "[0.0049621  0.00782353 0.0087966  ... 0.         0.         0.        ]\n",
      "[0.00860813 0.01153974 0.00972141 ... 0.         0.         0.        ]\n",
      "[0.0016703  0.00336014 0.0061584  ... 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "from skimage import color\n",
    "from skimage import feature\n",
    "import numpy as np\n",
    "\n",
    "def extrac_image_features(image_url):\n",
    "    #Read image\n",
    "    image = io.imread(image_url)\n",
    "    \n",
    "    #Preprocess image\n",
    "    width = 255\n",
    "    height = 255\n",
    "    image = resize(image, (width, height))#Ensuring all images have the same dimension\n",
    "    greyscale_image = color.rgb2gray(image)#Restricting the dimension of our data from 3D to 2D\n",
    "    \n",
    "    #Extract features\n",
    "    descs, descs_img = feature.daisy(greyscale_image, step=180, radius=58, rings=2, histograms=6,\n",
    "                         orientations=8, visualize=True)\n",
    "    edges1 = feature.canny(greyscale_image)\n",
    "    edges2 = feature.canny(greyscale_image, sigma=0.3)\n",
    "    descs = descs.ravel()\n",
    "    edges1 = edges1.ravel()\n",
    "    edges2 = edges2.ravel()\n",
    "    featureVector = np.concatenate((descs, edges1, edges2))\n",
    "    return featureVector\n",
    "\n",
    "numVQs = 4\n",
    "for vq in trainingData[0:numVQs]:\n",
    "    image_name = vq['image']\n",
    "    image_url = img_dir + image_name\n",
    "    #print(image_url)\n",
    "    image_feature = extrac_image_features(image_url)\n",
    "    print(image_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "from functools import reduce\n",
    "\n",
    "X_train = []\n",
    "X_val = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "for vq in trainingData[0:800]:\n",
    "    # Question features\n",
    "    question = vq['question']\n",
    "    question_feature = extract_language_features(question)\n",
    "    question_feature = np.array(question_feature)\n",
    "    \n",
    "    #Image features\n",
    "    image_name = vq['image']\n",
    "    image_url = img_dir + image_name\n",
    "    image_feature = extrac_image_features(image_url)\n",
    "    #print(np.array(image_feature).shape)\n",
    "       \n",
    "    #Concatenate the question and image features\n",
    "    multimodal_features = np.concatenate((question_feature, image_feature), axis = None)\n",
    "    #features = np.append(features, np.array(multimodal_features), axis = 1)\n",
    "    X_train.append(multimodal_features)\n",
    "    #print(multimodal_features)\n",
    "    #print(multimodal_features.shape)\n",
    "    \n",
    "    #Exreact labels\n",
    "    label = vq['answerable']\n",
    "    y_train.append(label)\n",
    "print('Done')\n",
    "#print(features)\n",
    "#print(reduce(operator.add, features))\n",
    "#print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "for vq in validationData[0:300]:\n",
    "    # Question features\n",
    "    question = vq['question']\n",
    "    question_feature = extract_language_features(question)\n",
    "    question_feature = np.array(question_feature)\n",
    "    \n",
    "    #Image features\n",
    "    image_name = vq['image']\n",
    "    image_url = img_dir + image_name\n",
    "    image_feature = extrac_image_features(image_url)\n",
    "       \n",
    "    #Concatenate the question and image features\n",
    "    multimodal_features = np.concatenate((question_feature, image_feature), axis = None)\n",
    "    X_val.append(multimodal_features)\n",
    "    \n",
    "    #Exreact labels\n",
    "    label = vq['answerable']\n",
    "    y_val.append(label)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "for vq in testingData[100:200]:\n",
    "    # Question features\n",
    "    question = vq['question']\n",
    "    question_feature = extract_language_features(question)\n",
    "    question_feature = np.array(question_feature)\n",
    "    \n",
    "    #Image features\n",
    "    image_name = vq['image']\n",
    "    image_url = img_dir + image_name\n",
    "    image_feature = extrac_image_features(image_url)\n",
    "       \n",
    "    #Concatenate the question and image features\n",
    "    multimodal_features = np.concatenate((question_feature, image_feature), axis = None)\n",
    "    X_test.append(multimodal_features)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.transpose(y_train)\n",
    "y_val = np.transpose(y_val)\n",
    "\n",
    "np.save('X_train.npy', X_train)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('X_val.npy', X_val)\n",
    "np.save('y_val.npy', y_val)\n",
    "np.save('X_test.npy', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X_train.npy')\n",
    "X_val = np.load('X_val.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "y_val = np.load('y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 130156)\n",
      "(300, 130156)\n",
      "(100, 130156)\n",
      "(800,)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=7)\n",
    "pca.fit(X_train)\n",
    "\n",
    "#cum_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "#nPC = np.min(np.where(cum_var >= 0.90)) + 1\n",
    "\n",
    "X_train_reduced = pca.transform(X_train)\n",
    "X_val_reduced = pca.transform(X_val)\n",
    "X_test_reduced = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6966666666666667"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gaussian_clf = GaussianNB()\n",
    "gaussian_clf.fit(X_train_reduced, y_train)\n",
    "val_pred = gaussian_clf.predict(X_val_reduced)\n",
    "val_accuracy = accuracy_score(y_val, val_pred)\n",
    "val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6966666666666667"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_reduced, y_train)\n",
    "val_pred_1 = lr_clf.predict(X_val_reduced)\n",
    "val_accuracy_1 = accuracy_score(y_val, val_pred)\n",
    "val_accuracy_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6966666666666667"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(C=7, degree=2, gamma=0.1, kernel='rbf')\n",
    "svm_clf.fit(X_train_reduced, y_train)\n",
    "val_pred_2 = svm_clf.predict(X_val_reduced)\n",
    "val_accuracy_2 = accuracy_score(y_val, val_pred)\n",
    "val_accuracy_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "y_test = gaussian_clf.predict(X_test_reduced)\n",
    "print(y_test)\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Prediction.csv',y_test,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd_data = pd.DataFrame(y_test, columns=['Prediction'])\n",
    "#print(pd_data)\n",
    "pd_data.to_csv('prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
